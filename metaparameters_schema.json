{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "title": "Trojan Detection Container (trojai-example) - Perspecta-PurdueRutgers v1.3",
  "technique": "Jacobian Feature GradientBoosting Classifier",
  "technique_description": "Extract Jacobian matrix w.r.t certain class input, train a GB classifier",
  "technique_changes": "output probability with calibration and add output logits into feature vector",
  "commit_id": "ff3270fa1fceebfda4458e1ee4659073c6b84c18",
  "repo_name": "git@github.com:SolidShen/Trojai_Round12_Jacobian.git",
  "required": [],
  "additionalProperties": false,
  "type": "object",
  "properties": {

	"train_jacobian_param_if_noise": {
		"description": "whether use noise or clean inputs to compute jacobian",
		"type": "boolean",
		"default": false
	},

	"train_jacobian_param_noise_scale": {
		"description": "noise scale",
		"type": "number",
		"minimum": 0,
		"maximum": 1,
		"suggested_minimum": 0,
		"suggested_maximum": 1
	},


	"train_jacobian_param_n_samples": {
		"description": "number of samples to use for Jacobian computation",
		"type": "number",
		"minimum": 10,
		"maximum": 10000,
		"suggested_minimum": 10,
		"suggested_maximum": 1000
	},


	"train_jacobian_param_sample_classes": {
		"description": "list of classes to use for Jacobian computation",
		"type": "string",
		"enum": ["0", "1", "both"]
	},
	

	"train_jacobian_param_aggr_method": {
		"description": "Function to aggreate the Jacobian matrix.",
		"type": "string",
		"enum": ["mean", "max", "min"]
	},


	

	"train_jacobian_param_if_reduce_dim": {
		"description": "whether reduce feature dimension of jacobian matrix",
		"type": "boolean",
		"default": false
	},




	"train_gradient_boosting_param_n_estimators": {
		"description": "Number of estimators in the classifier.",
		"type": "integer",
		"minimum": 1,
		"maximum": 8000,
		"suggested_minimum": 1000,
		"suggested_maximum": 5000
	},


	"train_gradient_boosting_param_learning_rate": {
		"description": "Learning rate",
		"type": "number",
		"minimum": 0.0,
		"maximum": 1.0,
		"suggested_minimum": 0.0,
		"suggested_maximum": 1e-2
	},

	"train_gradient_boosting_param_max_depth": {
		"description": "The maximum depth of the tree",
		"type": "integer",
		"minimum": 1,
		"maximum": 20,
		"suggested_minimum": 1,
		"suggested_maximum": 20
	},

	"train_gradient_boosting_param_subsample": {
		"description": "The minimum number of samples required to split an internal node.",
		"type": "number",
		"minimum": 0,
		"maximum": 5,
		"suggested_minimum": 0,
		"suggested_maximum": 2
	},

	"train_gradient_boosting_param_max_features": {
		"description": "The number of features to consider when looking for the best split.",
		"type": "string",
		"enum": ["sqrt"]
	},

	"train_gradient_boosting_param_loss": {
		"description": "The loss function to be optimized.",
		"type": "string",
		"enum": ["log_loss"]
	}


  }
}